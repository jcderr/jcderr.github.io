---
layout: post
status: publish
published: true
title: Kubernetes for Developers. No, Really.
author:
  display_name: jeremy.derr
  login: jeremy.derr
  email: jeremy@derr.me
  url: ''
author_login: jeremy.derr
author_email: jeremy@derr.me
wordpress_id: 233
wordpress_url: http://continuously.me/?p=233
date: '2015-10-03 22:09:15 -0500'
date_gmt: '2015-10-04 03:09:15 -0500'
categories:
- Uncategorized
tags: []
comments: []
---
<p>I've transitioned a lot of my production workload into a <a href="kubernetes.io">kubernetes</a> cluster, and we're shortly going to begin moving over some of our product too. I've been using fairly vanilla <a href="http://docker.com">Docker</a> for some of my local development toolset, though.</p></p>
<p>Once upon a time, I ran postgresql natively on my Mac, first by installing the official packages and later with <code>brew install postgresql</code>. Later, I started running my local postgresql in a Docker container. The same was roughly true for all of my other requirements, such as memcached or redis or rabbitmq.</p></p>
<p>If I just <code>docker run ...</code> these prerequisites, I now have to make sure they're still running at any given point in time. While moving to Docker brings me a tremendous ease-of-provisioning that I cannot ignore, this aspect is a regression; no longer can I use something like launchd to keep the service running if it fails. I could, and have, used <code>docker-compose</code> to create services in each project that provide the necessary software, but this has often lead me to running two or three copies of, say, postgresql at a time, if I don't remember to shut them down when I'm done.</p></p>
<p>And really, that's more than a little overkill. My local databases aren't performance tweaked. They aren't (generally) set up with any custom configuration, and to whatever degree they are, they're fairly generic tweaks that I apply to all of my databases. For dev, all that really matters is that I happen to have a postgres process running and the software has access to it. Why run three copies?</p></p>
<p>A few assumptions I make:</p></p>
<ul>
<li>I prefer my VM to be at <code>172.31.255.254</code>, as this private subnet is practically never used. By anyone. Ever.</li>
<li><code>~/src</code> is shared into the VM at <code>~core/src</code> and, thus, available to containers with the <code>-v</code> flag.</li>
<li>Kubernetes services are NodePorts. I replace the thousands digit with <code>30</code>; that is, the standard postgres <code>5432</code> port is comes out on <code>30432</code>.</li><br />
</ul></p>
<h1>Vagrantfile</h1></p>
<p>My <code>Vagrantfile</code> is based off of <a href="https://github.com/jimbojsb/docker-vm/">a great setup</a> by <a href="http://twitter.com/jimbojsb">Josh Butts</a> over at <a href="http://offers.com/">offers.com</a>. I added setup for etcd, fleet, and flannel, and added the units for all of the kubernetes components. You can find my setup <a href="https://github.com/jcderr/docker-kube-vm">here</a>. <code>vagrant up</code> and you're good to go. From Josh's setup, you can expose your services to the world by adding ports to the <code>services</code> file.</p></p>
<h1>Kubes</h1></p>
<p>The four most common services I use are mysql, postgresql, rabbitmq, and redis. Since I don't apply any tweaks on my dev box, I'm using the generic, official Docker images.</p></p>
<pre><code>$ kubectl create -f <service>/rc.yaml<br />
$ kubectl create -f <service>/service.yaml<br />
</code></pre></p>
<p>The services store their state in <code>/home/core/data/<service></code>. If I wind up with data I need, this is what I back up. You might be tempted to share this back out, but POSIX does stupid things sometimes and, chiefly, I've found it really messes with postgresql.</p></p>
<p>My example kubes are <a href="https://github.com/jcderr/kubes">here</a>.</p></p>
<h1>Docker</h1></p>
<p>Because this is based on Josh's setup, Docker is exposed outside the VM and I can use <code>docker run ...</code> and other commands locally on my Mac with the correct environment, without necessarily having to rely on kubernetes.</p></p>
<pre><code>$ export DOCKER_HOST=tcp://172.31.255.254:2375<br />
$ docker run ...<br />
    or<br />
$ docker-compose up<br />
</code></pre></p>
<p>Generally, I use <code>docker-compose</code> while developing, then test it by running it in my local kubelet before pushing it out to our production kubelets.</p></p>
